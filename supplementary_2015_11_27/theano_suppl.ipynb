{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano の 補講\n",
    "=======\n",
    "\n",
    "担当者　小川 兼司\n",
    "\n",
    "誤解を恐れず書いている部分もあるので、その点ご了承下さい。\n",
    "\n",
    "\n",
    "## 私見   Thenoについて\n",
    "\n",
    "機械学習、Deeplearningのツールは色々ありますが、\n",
    "\n",
    "* Deeplearningの仕組みを理解しながらコードを書く\n",
    "\n",
    "* 手っ取り早くGPUを使う\n",
    "\n",
    "* pythonでコードを書く\n",
    "\n",
    "という場合はTheanoがベスト\n",
    "\n",
    "\n",
    "## 他のライブラリとの比較\n",
    "\n",
    "Caffe, Torch, Chainer　\n",
    "    \n",
    "    各層のブロックを積み重ねるという考え方(既成のコード(関数)の積み重ね)\n",
    "\n",
    "    GPUを使用したままでのカスタマイズは困難（もともとそういう目的で作られてない）\n",
    "\n",
    "Theano\n",
    "    \n",
    "    各層のもとになる関数を自分で書く事ができる(C/C++, GPU用のコードが実行時に生成、コンパイルされる)\n",
    "    \n",
    "    Neural Networkの為の仕組みは用意されている\n",
    "    \n",
    "    Theano特有の文法を知っている必要がある\n",
    "    \n",
    "\n",
    "## GPUについて知っておいて欲しい事\n",
    "\n",
    "Graphics Processing Unit の略, CPUの外部にあるデバイス\n",
    "\n",
    "Deeplearning、科学技術などの数値計算で使われるのはほとんどNvidiaの製品 (Tesla, GeForce)\n",
    "\n",
    "本来の用途は画像処理、たくさんの小さい演算装置の集まり\n",
    "\n",
    "    SIMD (single instruction multiple data)\n",
    "\n",
    "    (3 color + transparency) のデータを一まとまりにする (4 unsigned int) => 4 sp float, 2 dp float\n",
    "\n",
    "    single precisionの最適化されたコードとdouble precisionの最適化されたコードは全く違う。\n",
    "\n",
    "GPUのメモリはCPUとは全く別のところにある。\n",
    "\n",
    "CUDAというプラットフォームを使用 (C/C++に近いコーディング。Theanoを使う場合はGPUの仕組み、GPU特有のコーディングについて\"それほど\"意識しなくてもいい)\n",
    "\n",
    "とりありず、以下の２つだけは心に留めておいて下さい\n",
    "\n",
    "* ### GPU は SIMDしか高速化できない\n",
    "\n",
    "* ### GPUに渡すデータの並び順は高速化をする上で重要\n",
    "\n",
    "\n",
    "## Theanoを使う上での注意\n",
    "\n",
    "* ### GPUで高速化できるのは float32(単精度浮動小数) の計算のみ\n",
    "\n",
    "    これはTheano特有の問題\n",
    "\n",
    "#### 参照\n",
    "\n",
    "Theano\n",
    "\n",
    "    http://deeplearning.net/software/theano/tutorial/\n",
    "\n",
    "Deeplearning Tutorial\n",
    "\n",
    "    http://deeplearning.net/tutorial/contents.html\n",
    "\n",
    "Theano製作者の論文（Theanoを使った研究論文を書く時にはリファレンスに入れる）\n",
    "\n",
    "    http://deeplearning.net/software/theano/citation.html\n",
    "\n",
    "誰かのブログ（よく書けてます）\n",
    "\n",
    "    http://aidiary.hatenablog.com/entry/20150509/1431137590\n",
    "    \n",
    "\n",
    "GPU (CUDA)\n",
    "\n",
    "    http://www.nvidia.co.jp/object/cuda-jp.html\n",
    "\n",
    "\n",
    "Libraryの比較について\n",
    "\n",
    "    http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html\n",
    "\n",
    "    http://fastml.com/torch-vs-theano/\n",
    "\n",
    "\n",
    "Thenoを使ったライブラリ\n",
    "\n",
    "    Keras\n",
    "    https://github.com/fchollet/keras\n",
    "    \n",
    "    Lasagne(ラザニア)\n",
    "    https://lasagne.readthedocs.org/en/latest/\n",
    "    \n",
    "    Blocks\n",
    "    https://github.com/mila-udem/blocks\n",
    "    \n",
    "    その他 github\n",
    "    https://github.com/search?utf8=%E2%9C%93&q=Theano&type=Repositories&ref=searchresults\n",
    "    \n",
    "\n",
    "                                                                                                            (cell 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## このノートに書いた事（順不同）\n",
    "\n",
    "* theanoに用意されている関数\n",
    "    tanh, sigmoid\n",
    "\n",
    "* theano.function　の使い方\n",
    "\n",
    "* givens の使い方\n",
    "\n",
    "* theano.shared と　theano.tensor.scalar, theano.tensor.vectorなどの違い\n",
    "\n",
    "* 乱数について\n",
    "\n",
    "* grad, updates　の使い方\n",
    "\n",
    "* その他の注意点\n",
    "\n",
    "(cell 1.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano にはどんな関数があるか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 820M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ARange',\n",
       " 'AdvancedIncSubtensor',\n",
       " 'AdvancedIncSubtensor1',\n",
       " 'AdvancedIndexingError',\n",
       " 'AdvancedSubtensor',\n",
       " 'AdvancedSubtensor1',\n",
       " 'Alloc',\n",
       " 'Apply',\n",
       " 'AsTensorError',\n",
       " 'CAReduce',\n",
       " 'Choose',\n",
       " 'Constant',\n",
       " 'Default',\n",
       " 'Diag',\n",
       " 'Diagonal',\n",
       " 'DiffOp',\n",
       " 'DimShuffle',\n",
       " 'DisconnectedType',\n",
       " 'Dot',\n",
       " 'Elemwise',\n",
       " 'EmptyConstantError',\n",
       " 'Eye',\n",
       " 'Flatten',\n",
       " 'Generic',\n",
       " 'IncSubtensor',\n",
       " 'Join',\n",
       " 'LoadFromDisk',\n",
       " 'Lop',\n",
       " 'MPIRecv',\n",
       " 'MPIRecvWait',\n",
       " 'MPISend',\n",
       " 'MPISendWait',\n",
       " 'MakeSlice',\n",
       " 'MaxAndArgmax',\n",
       " 'Mean',\n",
       " 'MethodNotDefined',\n",
       " 'NoneConst',\n",
       " 'NoneTypeT',\n",
       " 'Nonzero',\n",
       " 'NotScalarConstantError',\n",
       " 'NumpyAutocaster',\n",
       " 'Op',\n",
       " 'PermuteRowElements',\n",
       " 'Rebroadcast',\n",
       " 'Reshape',\n",
       " 'Rop',\n",
       " 'ScalarFromTensor',\n",
       " 'Shape',\n",
       " 'ShapeError',\n",
       " 'SliceConstant',\n",
       " 'SliceType',\n",
       " 'SpecifyShape',\n",
       " 'Split',\n",
       " 'Subtensor',\n",
       " 'SubtensorPrinter',\n",
       " 'Sum',\n",
       " 'Tensor',\n",
       " 'TensorConstant',\n",
       " 'TensorConstantSignature',\n",
       " 'TensorFromScalar',\n",
       " 'TensorType',\n",
       " 'TensorVariable',\n",
       " 'Tile',\n",
       " 'Tri',\n",
       " 'Type',\n",
       " 'Variable',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__docformat__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '_shared',\n",
       " '_tensor_py_operators',\n",
       " 'abs_',\n",
       " 'add',\n",
       " 'addbroadcast',\n",
       " 'adv_index_broadcastable_pattern',\n",
       " 'advanced_inc_subtensor',\n",
       " 'advanced_inc_subtensor1',\n",
       " 'advanced_set_subtensor',\n",
       " 'advanced_set_subtensor1',\n",
       " 'advanced_subtensor',\n",
       " 'advanced_subtensor1',\n",
       " 'all',\n",
       " 'all_dtypes',\n",
       " 'alloc',\n",
       " 'and_',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'arange',\n",
       " 'arccos',\n",
       " 'arccosh',\n",
       " 'arcsin',\n",
       " 'arcsinh',\n",
       " 'arctan',\n",
       " 'arctan2',\n",
       " 'arctanh',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_index_variable',\n",
       " 'as_int_none_variable',\n",
       " 'as_tensor',\n",
       " 'as_tensor_variable',\n",
       " 'autocast_float',\n",
       " 'autocast_float_as',\n",
       " 'autocast_int',\n",
       " 'bartlett',\n",
       " 'basic',\n",
       " 'batched_dot',\n",
       " 'batched_tensordot',\n",
       " 'bcol',\n",
       " 'bincount',\n",
       " 'bitwise_and',\n",
       " 'bitwise_not',\n",
       " 'bitwise_or',\n",
       " 'bitwise_xor',\n",
       " 'blas',\n",
       " 'blas_c',\n",
       " 'blas_headers',\n",
       " 'blas_scipy',\n",
       " 'bmatrix',\n",
       " 'brow',\n",
       " 'bscalar',\n",
       " 'btensor3',\n",
       " 'btensor4',\n",
       " 'bvector',\n",
       " 'cast',\n",
       " 'ccol',\n",
       " 'ceil',\n",
       " 'ceil_intdiv',\n",
       " 'check_equal_numpy',\n",
       " 'chi2sf',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'cmatrix',\n",
       " 'col',\n",
       " 'cols',\n",
       " 'compile',\n",
       " 'complex',\n",
       " 'complex_dtypes',\n",
       " 'complex_from_polar',\n",
       " 'complex_matrix_types',\n",
       " 'complex_scalar_types',\n",
       " 'complex_types',\n",
       " 'complex_vector_types',\n",
       " 'concatenate',\n",
       " 'config',\n",
       " 'conj',\n",
       " 'consider_constant',\n",
       " 'constant',\n",
       " 'constant_cache',\n",
       " 'constant_or_value',\n",
       " 'constructor',\n",
       " 'continuous_dtypes',\n",
       " 'copy',\n",
       " 'cos',\n",
       " 'cosh',\n",
       " 'crow',\n",
       " 'cscalar',\n",
       " 'ctensor3',\n",
       " 'ctensor4',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'cvector',\n",
       " 'dcol',\n",
       " 'dcols',\n",
       " 'dedent',\n",
       " 'default',\n",
       " 'deg2rad',\n",
       " 'diag',\n",
       " 'diagonal',\n",
       " 'discrete_dtypes',\n",
       " 'div_proxy',\n",
       " 'divmod',\n",
       " 'dmatrices',\n",
       " 'dmatrix',\n",
       " 'dot',\n",
       " 'drow',\n",
       " 'drows',\n",
       " 'dscalar',\n",
       " 'dscalars',\n",
       " 'dtensor3',\n",
       " 'dtensor3s',\n",
       " 'dtensor4',\n",
       " 'dtensor4s',\n",
       " 'dvector',\n",
       " 'dvectors',\n",
       " 'elemwise',\n",
       " 'elemwise_cgen',\n",
       " 'eq',\n",
       " 'erf',\n",
       " 'erfc',\n",
       " 'erfcinv',\n",
       " 'erfinv',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'expm1',\n",
       " 'extra_ops',\n",
       " 'extract_constant',\n",
       " 'eye',\n",
       " 'fcol',\n",
       " 'fcols',\n",
       " 'fill',\n",
       " 'fill_diagonal',\n",
       " 'fill_diagonal_offset',\n",
       " 'flatnonzero',\n",
       " 'flatten',\n",
       " 'float32_atol',\n",
       " 'float32_rtol',\n",
       " 'float64_atol',\n",
       " 'float64_rtol',\n",
       " 'float_dtypes',\n",
       " 'float_matrix_types',\n",
       " 'float_scalar_types',\n",
       " 'float_types',\n",
       " 'float_vector_types',\n",
       " 'floor',\n",
       " 'floor_div',\n",
       " 'fmatrices',\n",
       " 'fmatrix',\n",
       " 'frow',\n",
       " 'frows',\n",
       " 'fscalar',\n",
       " 'fscalars',\n",
       " 'ftensor3',\n",
       " 'ftensor3s',\n",
       " 'ftensor4',\n",
       " 'ftensor4s',\n",
       " 'fvector',\n",
       " 'fvectors',\n",
       " 'gamma',\n",
       " 'gammaln',\n",
       " 'ge',\n",
       " 'get_canonical_form_slice',\n",
       " 'get_idx_list',\n",
       " 'get_scalar_constant_value',\n",
       " 'get_scalar_constant_value_elemwises',\n",
       " 'get_vector_length',\n",
       " 'gof',\n",
       " 'grad',\n",
       " 'grad_not_implemented',\n",
       " 'grad_undefined',\n",
       " 'gt',\n",
       " 'hashtype',\n",
       " 'hessian',\n",
       " 'horizontal_stack',\n",
       " 'icol',\n",
       " 'icols',\n",
       " 'identity_like',\n",
       " 'imag',\n",
       " 'imatrices',\n",
       " 'imatrix',\n",
       " 'inc_subtensor',\n",
       " 'inplace_increment',\n",
       " 'int_div',\n",
       " 'int_dtypes',\n",
       " 'int_matrix_types',\n",
       " 'int_scalar_types',\n",
       " 'int_types',\n",
       " 'int_vector_types',\n",
       " 'inv',\n",
       " 'inverse_permutation',\n",
       " 'invert',\n",
       " 'io',\n",
       " 'irecv',\n",
       " 'iround',\n",
       " 'irow',\n",
       " 'irows',\n",
       " 'iscalar',\n",
       " 'iscalars',\n",
       " 'isend',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'itensor3',\n",
       " 'itensor3s',\n",
       " 'itensor4',\n",
       " 'itensor4s',\n",
       " 'ivector',\n",
       " 'ivectors',\n",
       " 'izip',\n",
       " 'jacobian',\n",
       " 'join',\n",
       " 'key_to_cmp',\n",
       " 'largest',\n",
       " 'lcol',\n",
       " 'lcols',\n",
       " 'le',\n",
       " 'lmatrices',\n",
       " 'lmatrix',\n",
       " 'load',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log1p',\n",
       " 'log2',\n",
       " 'logging',\n",
       " 'lrow',\n",
       " 'lrows',\n",
       " 'lscalar',\n",
       " 'lscalars',\n",
       " 'lt',\n",
       " 'ltensor3',\n",
       " 'ltensor3s',\n",
       " 'ltensor4',\n",
       " 'ltensor4s',\n",
       " 'lvector',\n",
       " 'lvectors',\n",
       " 'makeKeepDims',\n",
       " 'make_constant',\n",
       " 'make_slice',\n",
       " 'matrices',\n",
       " 'matrix',\n",
       " 'max',\n",
       " 'max_and_argmax',\n",
       " 'maximum',\n",
       " 'maxsize',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'min_informative_str',\n",
       " 'minimum',\n",
       " 'mod',\n",
       " 'mod_check',\n",
       " 'mpi_cmps',\n",
       " 'mpi_enabled',\n",
       " 'mpi_keys',\n",
       " 'mpi_send_wait_cmp',\n",
       " 'mpi_send_wait_key',\n",
       " 'mpi_tag_cmp',\n",
       " 'mpi_tag_key',\n",
       " 'mul',\n",
       " 'neg',\n",
       " 'neq',\n",
       " 'nlinalg',\n",
       " 'nnet',\n",
       " 'none_type_t',\n",
       " 'nonzero',\n",
       " 'nonzero_values',\n",
       " 'numeric_grad',\n",
       " 'numpy',\n",
       " 'numpy_scalar',\n",
       " 'old_shape',\n",
       " 'ones',\n",
       " 'ones_like',\n",
       " 'opt',\n",
       " 'opt_uncanonicalize',\n",
       " 'or_',\n",
       " 'os',\n",
       " 'outer',\n",
       " 'partial',\n",
       " 'patternbroadcast',\n",
       " 'permute_row_elements',\n",
       " 'pow',\n",
       " 'power',\n",
       " 'pprint',\n",
       " 'printing',\n",
       " 'prod',\n",
       " 'psi',\n",
       " 'ptp',\n",
       " 'python_all',\n",
       " 'python_any',\n",
       " 'python_complex',\n",
       " 'rad2deg',\n",
       " 'raw_random',\n",
       " 'real',\n",
       " 'recv',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'roll',\n",
       " 'round',\n",
       " 'round_half_away_from_zero',\n",
       " 'round_half_to_even',\n",
       " 'row',\n",
       " 'rows',\n",
       " 'scal',\n",
       " 'scalar',\n",
       " 'scalar_from_tensor',\n",
       " 'scalars',\n",
       " 'second',\n",
       " 'send',\n",
       " 'set_subtensor',\n",
       " 'setdefault',\n",
       " 'sgn',\n",
       " 'shape',\n",
       " 'shape_padleft',\n",
       " 'shape_padright',\n",
       " 'shared_randomstreams',\n",
       " 'sharedvar',\n",
       " 'signal',\n",
       " 'sin',\n",
       " 'sinh',\n",
       " 'slicetype',\n",
       " 'smallest',\n",
       " 'sort',\n",
       " 'sparse_module_ref',\n",
       " 'specify_shape',\n",
       " 'split',\n",
       " 'sqr',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'stacklists',\n",
       " 'std',\n",
       " 'sub',\n",
       " 'subtensor',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'switch',\n",
       " 'sys',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'tensor',\n",
       " 'tensor3',\n",
       " 'tensor3s',\n",
       " 'tensor4',\n",
       " 'tensor4s',\n",
       " 'tensor_copy',\n",
       " 'tensor_from_scalar',\n",
       " 'tensordot',\n",
       " 'theano',\n",
       " 'tile',\n",
       " 'transpose',\n",
       " 'tri',\n",
       " 'tril',\n",
       " 'triu',\n",
       " 'true_div',\n",
       " 'trunc',\n",
       " 'type',\n",
       " 'type_other',\n",
       " 'uint_dtypes',\n",
       " 'unbroadcast',\n",
       " 'utils',\n",
       " 'var',\n",
       " 'vector',\n",
       " 'vectors',\n",
       " 'verify_grad',\n",
       " 'vertical_stack',\n",
       " 'warnings',\n",
       " 'wcol',\n",
       " 'where',\n",
       " 'wmatrix',\n",
       " 'wrow',\n",
       " 'wscalar',\n",
       " 'wtensor3',\n",
       " 'wtensor4',\n",
       " 'wvector',\n",
       " 'xlogx',\n",
       " 'xor',\n",
       " 'zcol',\n",
       " 'zeros',\n",
       " 'zeros_like',\n",
       " 'zmatrix',\n",
       " 'zrow',\n",
       " 'zscalar',\n",
       " 'ztensor3',\n",
       " 'ztensor4',\n",
       " 'zvector']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 2\n",
    "import theano\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "dir(theano.tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apply',\n",
       " 'Conv3D',\n",
       " 'ConvGrad3D',\n",
       " 'ConvOp',\n",
       " 'ConvTransp3D',\n",
       " 'CrossentropyCategorical1Hot',\n",
       " 'CrossentropyCategorical1HotGrad',\n",
       " 'CrossentropySoftmax1HotWithBiasDx',\n",
       " 'CrossentropySoftmaxArgmax1HotWithBias',\n",
       " 'DisconnectedType',\n",
       " 'N',\n",
       " 'Prepend_scalar_constant_to_each_row',\n",
       " 'Prepend_scalar_to_each_row',\n",
       " 'Softmax',\n",
       " 'SoftmaxGrad',\n",
       " 'SoftmaxWithBias',\n",
       " 'T',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " 'binary_crossentropy',\n",
       " 'blas_header_text',\n",
       " 'blas_header_version',\n",
       " 'categorical_crossentropy',\n",
       " 'computeH',\n",
       " 'computeR',\n",
       " 'conv',\n",
       " 'conv2d',\n",
       " 'conv3D',\n",
       " 'convGrad3D',\n",
       " 'convTransp3D',\n",
       " 'crossentropy_categorical_1hot',\n",
       " 'crossentropy_categorical_1hot_grad',\n",
       " 'crossentropy_softmax_1hot',\n",
       " 'crossentropy_softmax_1hot_with_bias',\n",
       " 'crossentropy_softmax_1hot_with_bias_dx',\n",
       " 'crossentropy_softmax_argmax_1hot_with_bias',\n",
       " 'crossentropy_softmax_max_and_argmax_1hot',\n",
       " 'crossentropy_softmax_max_and_argmax_1hot_with_bias',\n",
       " 'crossentropy_to_crossentropy_with_softmax',\n",
       " 'crossentropy_to_crossentropy_with_softmax_with_bias',\n",
       " 'dmatrix',\n",
       " 'dvector',\n",
       " 'elemwise',\n",
       " 'fmatrix',\n",
       " 'fvector',\n",
       " 'gof',\n",
       " 'grad_not_implemented',\n",
       " 'grad_undefined',\n",
       " 'graph_merge_softmax_with_crossentropy_softmax',\n",
       " 'hard_sigmoid',\n",
       " 'ldflags',\n",
       " 'local_advanced_indexing_crossentropy_onehot',\n",
       " 'local_advanced_indexing_crossentropy_onehot_grad',\n",
       " 'local_argmax_pushdown',\n",
       " 'local_crossentropy_to_crossentropy_with_softmax_grad',\n",
       " 'local_log_softmax',\n",
       " 'local_softmax_with_bias',\n",
       " 'logging',\n",
       " 'make_out_pattern',\n",
       " 'neighbours',\n",
       " 'nnet',\n",
       " 'numpy',\n",
       " 'opt',\n",
       " 'optdb',\n",
       " 'prepend_0_to_each_row',\n",
       " 'prepend_1_to_each_row',\n",
       " 'prepend_scalar_to_each_row',\n",
       " 'scalar',\n",
       " 'scalar_sigmoid',\n",
       " 'sigm',\n",
       " 'sigmoid',\n",
       " 'sigmoid_inplace',\n",
       " 'softmax',\n",
       " 'softmax_grad',\n",
       " 'softmax_simplifier',\n",
       " 'softmax_with_bias',\n",
       " 'softplus',\n",
       " 'strutil',\n",
       " 'subtensor',\n",
       " 'tensor',\n",
       " 'theano',\n",
       " 'ultra_fast_sigmoid',\n",
       " 'values_eq_approx_remove_nan']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 3\n",
    "import theano\n",
    "dir(theano.tensor.nnet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# cell 4\n",
    "# Frequently used function in NN\n",
    "print 'tanh' in dir(theano.tensor)\n",
    "print 'sigmoid' in dir(theano.tensor.nnet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## theano.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('output must be a theano Variable or Out instance (or list of them)', array([ 1.,  1.,  1.]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9b4aadcc7985>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# You CANNOT DO this.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m f = theano.function([],\n\u001b[1;32m---> 11\u001b[1;33m                     np.ones(3))\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 profile=profile)\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    487\u001b[0m                                          \u001b[0mrebuild_strict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrebuild_strict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                                          \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                                          no_default_updates=no_default_updates)\n\u001b[0m\u001b[0;32m    490\u001b[0m     \u001b[1;31m# extracting the arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcloned_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_stuff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_vars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    252\u001b[0m             raise TypeError('output must be a theano Variable or Out '\n\u001b[0;32m    253\u001b[0m                             \u001b[1;34m'instance (or list of them)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                             outputs)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;31m# Iterate over update_expr, cloning its elements, and updating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('output must be a theano Variable or Out instance (or list of them)', array([ 1.,  1.,  1.]))"
     ]
    }
   ],
   "source": [
    "# cell 5\n",
    "import theano\n",
    "import numpy as np\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "\n",
    "\n",
    "# You CANNOT DO this.\n",
    "f = theano.function([],\n",
    "                    np.ones(3))\n",
    "\n",
    "f()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 6\n",
    "import theano\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "# You CAN DO this.\n",
    "f = theano.function([],\n",
    "                    theano.tensor.ones(3))\n",
    "\n",
    "f()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorType(float32, scalar)> <TensorType(float32, scalar)> Elemwise{add,no_inplace}.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# cell 7.1\n",
    "# Theano scalar, vector cannot have it's value\n",
    "# It's used to define function\n",
    "import theano\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "a = theano.tensor.scalar(dtype='float32')\n",
    "b = theano.tensor.scalar(dtype='float32')\n",
    "c = a + b\n",
    "print a, b, c\n",
    "\n",
    "tf_add = theano.function([a, b], c)\n",
    "\n",
    "print tf_add(1, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]\n"
     ]
    }
   ],
   "source": [
    "# cell 7.2\n",
    "# The memory are allocated for shared valiable\n",
    "\n",
    "import theano\n",
    "import numpy as np\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "x = theano.shared(np.arange(10, dtype='float32'))\n",
    "y = theano.shared(np.ones((10,)))\n",
    "\n",
    "print x.get_value()\n",
    "print y.get_value()\n",
    "print x.get_value() + y.get_value()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorType(float32, scalar)> <TensorType(float32, scalar)> Elemwise{add,no_inplace}.0\n",
      "13.0\n"
     ]
    }
   ],
   "source": [
    "# cell 7.3\n",
    "# givens\n",
    "\n",
    "import theano\n",
    "import numpy as np\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "a = theano.tensor.scalar(dtype='float32')\n",
    "b = theano.tensor.scalar(dtype='float32')\n",
    "c = a + b\n",
    "print a, b, c\n",
    "\n",
    "d = theano.shared(np.float32(10))\n",
    "tf_add = theano.function([a], c, givens={b: d})\n",
    "\n",
    "print tf_add(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# cell 7.4\n",
    "# grad\n",
    "import theano\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "tx = theano.tensor.vector(dtype='float32')\n",
    "ty = (tx * tx * tx).sum()\n",
    "\n",
    "grad_y = theano.grad(ty, tx)\n",
    "tf_grad_y = theano.function([tx], grad_y)\n",
    "\n",
    "x = np.ones(1, dtype='float32') * 0.5\n",
    "print tf_grad_y(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.0\n"
     ]
    }
   ],
   "source": [
    "# cell 7.5\n",
    "# update\n",
    "tx = theano.tensor.vector(dtype='float32')\n",
    "s = theano.shared(np.float32(0))\n",
    "\n",
    "tx = theano.tensor.scalar(dtype='float32')\n",
    "acumulate = theano.function([tx], updates={s: s + tx})\n",
    "\n",
    "# sum of 0, 1, 2, .... 10\n",
    "for i in range(11):\n",
    "    acumulate(i)\n",
    "print s.get_value()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 8\n",
    "# numpy binomial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState()\n",
    "rng.binomial(n=1, p=0.5, size=(10,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数定義時にされる事、関数実行時にされる事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 0 1 0 1]\n",
      "[1 0 1 0 1 1 1 1 0 1]\n",
      "[1 0 0 0 1 1 1 1 1 1]\n",
      "[0 1 1 0 0 0 0 0 0 0]\n",
      "[0 1 0 1 1 1 0 0 0 1]\n",
      "[0 1 1 1 0 0 1 0 1 0]\n",
      "[1 1 1 1 0 1 1 0 1 1]\n",
      "[1 0 1 0 0 0 0 0 0 1]\n",
      "[0 1 1 0 0 1 0 1 1 1]\n",
      "[0 0 0 1 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# cell 9.1\n",
    "import theano\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "srng = theano.tensor.shared_randomstreams.RandomStreams(123)\n",
    "binom = srng.binomial(n=1, p=0.5, size=(10,))\n",
    "\n",
    "tf_binomial = theano.function([], binom)\n",
    "\n",
    "for i in range(10):\n",
    "    print tf_binomial()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# cell 9.2\n",
    "import theano\n",
    "import numpy as np\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "rng = np.random.RandomState()\n",
    "binom = theano.shared(rng.binomial(n=1, p=0.5, size=(10,)))\n",
    "tf_binomial = theano.function([], binom)\n",
    "\n",
    "for i in range(10):\n",
    "    print tf_binomial()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell 9.1 において、theano.tensor.shared_randomstreams　を使わずに同じような結果を出すにはどうすればいいでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cell 9.3\n",
    "#import theano\n",
    "#import numpy as np\n",
    "#rng = np.random.RandomState()\n",
    "#binom = theano.shared(rng.binomial(n=1, p=0.5, size=(10*10,)))\n",
    "#i = theano.tensor.iscalar()\n",
    "#x = theano.tensor.vector('float32')\n",
    "#tf_binomial = theano.function(inputs=[i], outputs=x, givens={x:binom[i*10:(i+1)*10]})\n",
    "#\n",
    "# for i in range(10):\n",
    "#    print tf_binomial(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データタイプは常に明示的にするべきです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 int8\n",
      "128 int16\n",
      "-2\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# cell 10.1\n",
    "x = theano.tensor.constant(127)\n",
    "print x.get_scalar_constant_value(), x.dtype\n",
    "\n",
    "a = x.get_scalar_constant_value()\n",
    "\n",
    "x = theano.tensor.constant(128)\n",
    "print x.get_scalar_constant_value(), x.dtype\n",
    "\n",
    "b = x.get_scalar_constant_value()\n",
    "\n",
    "print a + a\n",
    "\n",
    "print b + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のセルの３行めはなぜこうなったのでしょうか？　これを127+127=254にするにはどうすればいいでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cell 10.2\n",
    "#x = theano.tensor.constant(127,dtype='int16')\n",
    "# print x.get_scalar_constant_value(), x.dtype\n",
    "#a = x.get_scalar_constant_value()\n",
    "# print a + a\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 微分不可能な点がある場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(1.0)] [array(0.0)] [array(0.0)]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "x = theano.tensor.scalar()\n",
    "y = x * (x>0)\n",
    "#y = x * (x>=0)\n",
    "d = theano.grad(y,[x])\n",
    "fd = theano.function([x],d)\n",
    "print fd(0.1), fd(0.0), fd(-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaNが現れるケース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4013e-45 0.0\n",
      "nan 0.0 0.0 nan\n",
      "1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "#import theano.sandbox.cuda\n",
    "#theano.sandbox.cuda.use(\"gpu0\")\n",
    "\n",
    "#x = theano.tensor.scalar(dtype='float64')\n",
    "x = theano.tensor.scalar(dtype='float32')\n",
    "\n",
    "y = (1.0/x) * x\n",
    "#y = (1.0/x)\n",
    "#y = (1.0/x) - (1.0/x)\n",
    "\n",
    "d = theano.grad(y,x)\n",
    "\n",
    "fd = theano.function([x], d)\n",
    "fy = theano.function([x], y)\n",
    "print np.float32(1.0e-45), np.float32(1.0e-46)\n",
    "print fd(0.0), fd(1.0e+310), fd(np.float32(1.0e-38)), fd(np.float32(1.0e-39))\n",
    "print fy(0.0), fy(1.0e+310), fy(np.float32(1.0e-38)), fy(np.float32(1.0e-39))\n",
    "#print fd(1.0e-308), fd(1.0e-309), fd(0.0), fd(1.0e+310), fd(1.e-38), fd(1.e-39)\n",
    "#print fy(1.0e-308), fy(1.0e-309), fy(0.0), fy(1.0e+310), fy(1.e-38), fy(1.e-39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 質問　theanoを使う上で初心者のハマりやすいところや知っとくとためになるコツがあれば教えていただきたいです "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私が知る限りではだいたい、このノートに書いたとおりです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 質問　theano.gradでは、任意の微分可能関数に対して微分は計算されるのでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'任意の'と聞かれたら、私は答えを知りません。\n",
    "\n",
    "たとえば、複素関数で複雑な多価関数になった場合など、私は一つ一つ調べたわけではないので分かり兼ねます。\n",
    "\n",
    "私の経験では機械学習で使用するほとんどの関数はtheanoで構成できて微分の計算ができます。\n",
    "\n",
    "数値計算上での有効桁数により制約をうける事もあります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
